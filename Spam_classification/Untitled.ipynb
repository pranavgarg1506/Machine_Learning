{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d1eb73cce75d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ggplot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import spacy\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import os.path\n",
    "\n",
    "class SMSBase:\n",
    "    # Spacy library is loading English dictionary.\n",
    "    _nlp = spacy.load(\"en\")\n",
    "    \n",
    "    def __init__(self, filename, frac=0.8):\n",
    "        self._filename = filename\n",
    "        self._features = ['class', 'context']\n",
    "        \n",
    "        self._df_raw = pd.read_csv(self._filename, sep='\\t', names=self._features)\n",
    "        self.__format_context()\n",
    "        \n",
    "        self.__extract_features()\n",
    "        \n",
    "        self._group_by_feature = self._df_raw .groupby('class')\n",
    "        self._counts_by_features = self._group_by_feature.count().to_dict()['context']\n",
    "        \n",
    "        self.__split_test_train(frac)\n",
    "        \n",
    "    def __format_context(self):\n",
    "        self._df_raw['context'] =  self._df_raw['context'].map(lambda text : text.rstrip())\n",
    "        self._df_raw['context'] =  self._df_raw['context'].map(lambda text : text.replace(',', ' ,') if ',' in text else text)\n",
    "    \n",
    "    def __extract_features(self):\n",
    "        self._df_raw['len']= self._df_raw['context'].map(lambda text : len(text))\n",
    "        self._df_raw['n_words'] = self._df_raw['context'].map(lambda text : len(text.split(' ')))\n",
    "\n",
    "        #updating features\n",
    "        self._features = self._df_raw.columns\n",
    "    \n",
    "    def __split_test_train(self, frac):\n",
    "        self._df_train = self._df_raw.sample(frac=frac)\n",
    "        self._df_test = self._df_raw.drop(self._df_train.index)\n",
    "    \n",
    "    def describe(self):\n",
    "        print('-' * 20 + 'Extended Dataset (Head)' + '-' * 20)\n",
    "        display(self._df_raw.head())\n",
    "        \n",
    "        print('-' * 20 + 'Extended Dataset (Describe)' + '-' * 20)\n",
    "        display(self._df_raw.describe())\n",
    "        \n",
    "        print('-' * 20 + 'Groupby Class (Describe)' + '-' * 20)\n",
    "        display(self._group_by_feature.describe())\n",
    "        \n",
    "    def create_lemmas(self, c):\n",
    "        tokens = self._nlp(c)\n",
    "        return [token.lemma_ for token in tokens]\n",
    "    \n",
    "    def create_tokens(self, c):\n",
    "        tokens = self._nlp(c)\n",
    "        return [token for token in tokens]\n",
    "    \n",
    "    \n",
    "class Util:\n",
    "        \n",
    "    def report_classification(model, df_train, df_test, X_features, y_feature):\n",
    "        \n",
    "        classes_train = np.unique(df_train[y_feature].values).tolist()\n",
    "        classes_test = np.unique(df_test[y_feature].values).tolist()\n",
    "        \n",
    "        assert (classes_train == classes_test)\n",
    "        \n",
    "        classes = classes_train # The order of class is important!\n",
    "        \n",
    "        X_train = df_train[X_features].values.tolist()\n",
    "        X_test = df_test[X_features].values.tolist()\n",
    "        \n",
    "        y_train = df_train[y_feature].values.tolist()\n",
    "        y_test = df_test[y_feature].values.tolist()\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        report_cm(y_train, y_test, y_train_pred, y_test_pred, classes)\n",
    "        \n",
    "    def report_cm(y_train, y_test, y_train_pred, y_test_pred, classes):\n",
    "        figure, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "        cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "        df_cm_test = pd.DataFrame(cm_test, index = classes, columns = classes)\n",
    "        ax = sns.heatmap(df_cm_test, annot=True, ax = axes[0], square= True)\n",
    "        ax.set_title('Test CM')\n",
    "\n",
    "        cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "        df_cm_train = pd.DataFrame(cm_train, index = classes, columns = classes)\n",
    "        ax = sns.heatmap(df_cm_train, annot=True, ax = axes[1], square= True)\n",
    "        ax.set_title('Train CM')\n",
    "\n",
    "        print('-' * 20 + 'Testing Performance' + '-' * 20)\n",
    "        print(classification_report(y_test, y_test_pred, target_names = classes))\n",
    "        print('acc: ', metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "        print('-' * 20 + 'Training Performance' + '-' * 20)\n",
    "        print(classification_report(y_train, y_train_pred, target_names = classes))\n",
    "        print('acc: ', metrics.accuracy_score(y_train, y_train_pred))\n",
    "        \n",
    "    \n",
    "    def plot_cdf(p, \n",
    "             ax, \n",
    "             deltax=None, \n",
    "             xlog=False, \n",
    "             xlim=[0, 1], \n",
    "             deltay=0.25, \n",
    "             ylog=False, \n",
    "             ylim=[0,1], \n",
    "             xlabel = 'x'):\n",
    "\n",
    "        df = pd.DataFrame(p, columns=[xlabel])\n",
    "        display(df.describe())\n",
    "        \n",
    "        ecdf = sm.distributions.ECDF(p)\n",
    "        x = ecdf.x\n",
    "        y = ecdf.y\n",
    "        assert len(x) == len(y)\n",
    "        if deltax is not None:\n",
    "            x_ticks = np.arange(xlim[0], xlim[1] + deltax, deltax)\n",
    "            ax.set_xticks(x_ticks)\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xlim(xlim[0], xlim[1])\n",
    "        ax.vlines(np.mean(p), min(y), max(y), color='red', label='mean', linewidth=2)\n",
    "        ax.vlines(np.median(p), min(y), max(y), color='orange', label='median', linewidth=2)\n",
    "        ax.vlines(np.mean(p) + 2 * np.std(p), min(y), max(y), color='blue', label='mean + 2 * std', linewidth=2)\n",
    "        ax.vlines(np.mean(p) + 3 * np.std(p), min(y), max(y), color='green', label='mean + 3 * std', linewidth=2)\n",
    "\n",
    "        y_ticks = np.arange(ylim[0], ylim[1] + deltay, deltay)\n",
    "        ax.set_ylabel('CDF')\n",
    "        ax.set_yticks(y_ticks)\n",
    "        ax.set_ylim(ylim[0], ylim[1])\n",
    "\n",
    "        if xlog is True:\n",
    "            ax.set_xscale('log')\n",
    "\n",
    "        if ylog is True:\n",
    "            ax.set_yscale('log')\n",
    "\n",
    "\n",
    "        ax.grid(which='minor', alpha=0.5)\n",
    "        ax.grid(which='major', alpha=0.9)\n",
    "\n",
    "        ax.legend(loc=4)\n",
    "\n",
    "        sns.set_style('whitegrid')\n",
    "        sns.regplot(x=x, y=y, fit_reg=False, scatter=True, ax = ax)\n",
    "    \n",
    "        \n",
    "    def plot_class_dist(df, by):\n",
    "        \n",
    "        x_features = df.columns.drop(by)\n",
    "        assert 0 < len(x_features)\n",
    "        \n",
    "        x_features = x_features[0]\n",
    "        dist = df.groupby(by)[x_features].size() / len(df)\n",
    "        display(dist)        \n",
    "        sns.barplot(x=dist.index, y=dist.values)\n",
    "        \n",
    "    def plot_boxplot(df, by, y, ax):\n",
    "        ax = sns.boxplot(x=by, y=y, data=df[[by,  y]], ax = ax)\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "    def dump_pickle(obj,filename):\n",
    "        joblib.dump(obj, filename)\n",
    "        \n",
    "    def load_pickle(filename):\n",
    "        return joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading https://files.pythonhosted.org/packages/55/2e/ac00f5c9d01e66cc6ab75eb2a460c9b0dc21ad99a12f810c86a58309e63c/spacy-2.2.4-cp36-cp36m-manylinux1_x86_64.whl (10.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.6MB 113kB/s ta 0:00:01    52% |████████████████▊               | 5.6MB 1.3MB/s eta 0:00:04    53% |█████████████████               | 5.7MB 1.4MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/47/55/fd9170ba08a1a64a18a7f8a18f088037316f2a41be04d2fe6ece5a653e8f/tqdm-4.43.0-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 961kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting setuptools (from spacy)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/df/635cdb901ee4a8a42ec68e480c49f85f4c59e8816effbf57d9e6ee8b3588/setuptools-46.1.3-py3-none-any.whl (582kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 593kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 484kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting srsly<1.1.0,>=1.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/0e/9a/70bd934dd4d25545c9aa6c8cd4edbac2a33ba9c915439a9209b69f0ec0ad/srsly-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (185kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 1.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.15.0 (from spacy)\n",
      "  Using cached https://files.pythonhosted.org/packages/07/08/a549ba8b061005bb629b76adc000f3caaaf881028b963c2e18f811c6edc1/numpy-1.18.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/b5/3e1714ebda8fd7c5859f9b216e381adc0a38b962f071568fd00d67e1b1ca/cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 813kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.5.0,>=0.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.7MB 280kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/21/e1/e4e7b754e6be3a79c400eb766fb34924a6d278c43bb828f94233e0124a21/wasabi-0.6.0-py3-none-any.whl\n",
      "Collecting thinc==7.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/ed/8e4559f1090fb05c0fa982a8a2caaa315967e7b460652be479d13fd1c813/thinc-7.4.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.2MB 289kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting plac<1.2.0,>=0.9.6 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n",
      "Collecting importlib-metadata>=0.20; python_version < \"3.8\" (from catalogue<1.1.0,>=0.0.7->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/e4/891bfcaf868ccabc619942f27940c77a8a4b45fd8367098955bb7e152fb1/importlib_metadata-1.6.0-py2.py3-none-any.whl\n",
      "Collecting chardet<4,>=3.0.2 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 641kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl (156kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 805kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting idna<3,>=2.5 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 816kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting zipp>=0.5 (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n",
      "Installing collected packages: tqdm, setuptools, zipp, importlib-metadata, catalogue, murmurhash, cymem, preshed, srsly, numpy, chardet, urllib3, certifi, idna, requests, blis, wasabi, plac, thinc, spacy\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 certifi-2019.11.28 chardet-3.0.4 cymem-2.0.3 idna-2.9 importlib-metadata-1.6.0 murmurhash-1.0.2 numpy-1.18.2 plac-1.1.3 preshed-3.0.2 requests-2.23.0 setuptools-46.1.3 spacy-2.2.4 srsly-1.0.2 thinc-7.4.0 tqdm-4.43.0 urllib3-1.25.8 wasabi-0.6.0 zipp-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
